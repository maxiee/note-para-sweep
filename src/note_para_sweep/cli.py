"""å‘½ä»¤è¡Œç•Œé¢"""

import click
from typing import Optional
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm
from rich.table import Table
from rich.text import Text

from .config import Config
from .scanner import DirectoryScanner
from .llm_client import LLMClient
from .file_operations import FileOperator


console = Console()


class LogFileManager:
    """æ—¥å¿—æ–‡ä»¶ç®¡ç†å™¨"""

    def __init__(self, log_file_path: Optional[str] = None):
        self.log_file_path = log_file_path
        self.session_started = False

    def start_session(self, command: str, config_info: dict):
        """å¼€å§‹æ–°çš„æ—¥å¿—ä¼šè¯"""
        if not self.log_file_path:
            return

        from datetime import datetime
        from pathlib import Path
        import sys

        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_path = Path(self.log_file_path)
            log_path.parent.mkdir(parents=True, exist_ok=True)

            with open(self.log_file_path, "a", encoding="utf-8") as f:
                if not self.session_started:
                    f.write(f"\n{'='*80}\n")
                    f.write(f"Note PARA Sweep - è¯¦ç»†æ—¥å¿—\n")
                    f.write(
                        f"ä¼šè¯å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    )
                    f.write(f"æ‰§è¡Œå‘½ä»¤: {command}\n")
                    f.write(f"Pythonç‰ˆæœ¬: {sys.version}\n")
                    f.write(f"é…ç½®ä¿¡æ¯: {config_info}\n")
                    f.write(f"{'='*80}\n\n")
                    self.session_started = True
        except Exception as e:
            console.print(
                f"[red]è­¦å‘Š: æ— æ³•å†™å…¥æ—¥å¿—æ–‡ä»¶ {self.log_file_path}: {e}[/red]"
            )
            self.log_file_path = None

    def write_log(self, message: str):
        """å†™å…¥æ—¥å¿—æ¶ˆæ¯"""
        if not self.log_file_path:
            return

        try:
            with open(self.log_file_path, "a", encoding="utf-8") as f:
                f.write(message + "\n")
        except Exception as e:
            # é™é»˜å¤±è´¥ï¼Œé¿å…å½±å“ä¸»ç¨‹åº
            pass


# å…¨å±€æ—¥å¿—æ–‡ä»¶ç®¡ç†å™¨
_log_manager = LogFileManager()


def verbose_log(message: str, verbose: bool = False, level: str = "info"):
    """æ¡ä»¶æ€§æ—¥å¿—è¾“å‡º

    Args:
        message: æ—¥å¿—æ¶ˆæ¯
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ¨¡å¼
        level: æ—¥å¿—çº§åˆ« (info, debug, warning, error)
    """
    if not verbose:
        return

    level_colors = {
        "debug": "dim cyan",
        "info": "cyan",
        "warning": "yellow",
        "error": "red",
    }

    color = level_colors.get(level, "white")
    prefix = f"[{level.upper()}]" if level != "info" else "[VERBOSE]"

    from datetime import datetime

    timestamp = datetime.now().strftime("%H:%M:%S")

    # æ§åˆ¶å°è¾“å‡º
    console.print(f"[dim]{timestamp}[/dim] [{color}]{prefix}[/{color}] {message}")

    # æ—¥å¿—æ–‡ä»¶è¾“å‡ºï¼ˆçº¯æ–‡æœ¬æ ¼å¼ï¼‰
    _log_manager.write_log(f"{timestamp} {prefix} {message}")


def verbose_log_json(label: str, data: dict, verbose: bool = False):
    """æ ¼å¼åŒ–è¾“å‡ºJSONæ•°æ®

    Args:
        label: æ•°æ®æ ‡ç­¾
        data: è¦è¾“å‡ºçš„å­—å…¸æ•°æ®
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ¨¡å¼
    """
    if not verbose:
        return

    from datetime import datetime
    import json

    timestamp = datetime.now().strftime("%H:%M:%S")

    # æ§åˆ¶å°è¾“å‡º
    console.print(f"\n[dim]{timestamp}[/dim] [dim cyan]â”â”â” {label} â”â”â”[/dim cyan]")
    console.print_json(data=data)
    console.print(
        "[dim cyan]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[/dim cyan]"
    )

    # æ—¥å¿—æ–‡ä»¶è¾“å‡º
    _log_manager.write_log(f"\n{timestamp} â”â”â” {label} â”â”â”")
    _log_manager.write_log(json.dumps(data, ensure_ascii=False, indent=2))
    _log_manager.write_log("â”" * 50)


@click.group()
@click.option("--config", "-c", default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
@click.option("--dry-run", is_flag=True, help="è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…æ“ä½œ")
@click.option("--verbose", "-v", is_flag=True, help="è¯¦ç»†è¾“å‡ºæ¨¡å¼ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯")
@click.option(
    "--log-file", "-l", help="ä¿å­˜è¯¦ç»†æ—¥å¿—åˆ°æŒ‡å®šæ–‡ä»¶ï¼ˆéœ€è¦åŒæ—¶å¯ç”¨--verboseï¼‰"
)
@click.pass_context
def cli(ctx, config, dry_run, verbose, log_file):
    """Note PARA Sweep - AI é©±åŠ¨çš„ Obsidian ç¬”è®° PARA åˆ†ç±»å™¨"""
    ctx.ensure_object(dict)

    try:
        ctx.obj["config"] = Config(config)
        ctx.obj["dry_run"] = dry_run or ctx.obj["config"].dry_run_by_default
        ctx.obj["verbose"] = verbose
        ctx.obj["log_file"] = (
            log_file if verbose else None
        )  # åªæœ‰åœ¨verboseæ¨¡å¼ä¸‹æ‰å¯ç”¨æ—¥å¿—æ–‡ä»¶

        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶ç®¡ç†å™¨
        if ctx.obj["log_file"]:
            global _log_manager
            _log_manager = LogFileManager(ctx.obj["log_file"])

        # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        if ctx.invoked_subcommand:
            console.print(
                Panel(
                    "[bold blue]Note PARA Sweep[/bold blue]\n"
                    "AI é©±åŠ¨çš„ Obsidian ç¬”è®° PARA åˆ†ç±»å™¨",
                    title="æ¬¢è¿",
                    expand=False,
                )
            )

            if ctx.obj["dry_run"]:
                console.print(
                    "[yellow]âš ï¸  å½“å‰å¤„äºè¯•è¿è¡Œæ¨¡å¼ï¼Œä¸ä¼šæ‰§è¡Œå®é™…çš„æ–‡ä»¶æ“ä½œ[/yellow]"
                )

            if ctx.obj["log_file"]:
                console.print(f"[green]ğŸ“ æ—¥å¿—å°†ä¿å­˜åˆ°: {ctx.obj['log_file']}[/green]")

    except FileNotFoundError as e:
        console.print(f"[red]é…ç½®æ–‡ä»¶é”™è¯¯: {e}[/red]")
        console.print("[dim]æç¤º: è¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®[/dim]")
        raise click.Abort()
    except ValueError as e:
        console.print(f"[red]é…ç½®éªŒè¯é”™è¯¯: {e}[/red]")
        console.print("[dim]æç¤º: è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°è®¾ç½®[/dim]")
        raise click.Abort()
    except Exception as e:
        console.print(f"[red]åˆå§‹åŒ–é”™è¯¯: {e}[/red]")
        console.print("[dim]å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æˆ–è”ç³»æ”¯æŒ[/dim]")
        raise click.Abort()


@cli.command()
@click.pass_context
def scan(ctx):
    """æ‰«æ PARA ç›®å½•ç»“æ„"""
    config = ctx.obj["config"]
    verbose = ctx.obj["verbose"]
    log_file = ctx.obj["log_file"]

    # åˆå§‹åŒ–æ—¥å¿—ä¼šè¯
    if log_file:
        _log_manager.start_session(
            "scan",
            {
                "vault_path": str(config.vault_path),
                "para_paths": config.para_paths,
                "verbose": verbose,
                "log_file": log_file,
            },
        )

    console.print("[blue]æ­£åœ¨æ‰«æ PARA ç›®å½•ç»“æ„...[/blue]")
    verbose_log(f"æ‰«æç›®æ ‡è·¯å¾„: {config.vault_path}", verbose)
    verbose_log(f"PARA è·¯å¾„é…ç½®: {config.para_paths}", verbose)

    scanner = DirectoryScanner(config.vault_path, config.para_paths)
    scan_result = scanner.scan()

    verbose_log_json(
        "è¯¦ç»†æ‰«æç»“æœ",
        {
            "vault_path": str(config.vault_path),
            "scan_details": {
                path: {
                    "note_count": info.note_count,
                    "subdirs": [
                        {
                            "name": sub.name,
                            "note_count": sub.note_count,
                            "path": str(sub.path),
                        }
                        for sub in info.subdirs
                    ],
                }
                for path, info in scan_result.items()
            },
        },
        verbose,
    )

    # ç”Ÿæˆå¹¶æ˜¾ç¤ºç»“æ„æ‘˜è¦
    summary = scanner.generate_structure_summary(scan_result)
    console.print(Panel(summary, title="ç›®å½•ç»“æ„", expand=True))

    # ç»Ÿè®¡ä¿¡æ¯
    total_notes = sum(dir_info.note_count for dir_info in scan_result.values())
    console.print(f"\n[green]âœ… æ‰«æå®Œæˆï¼å…±å‘ç° {total_notes} ç¯‡ç¬”è®°[/green]")
    verbose_log(
        f"ç»Ÿè®¡è¯¦æƒ…: {[(path, info.note_count) for path, info in scan_result.items()]}",
        verbose,
    )


@cli.command()
@click.argument("note_path", type=click.Path(exists=True))
@click.pass_context
def classify(ctx, note_path):
    """åˆ†ç±»å•ä¸ªç¬”è®°æ–‡ä»¶"""
    config = ctx.obj["config"]
    dry_run = ctx.obj["dry_run"]
    verbose = ctx.obj["verbose"]
    log_file = ctx.obj["log_file"]

    # åˆå§‹åŒ–æ—¥å¿—ä¼šè¯
    if log_file:
        _log_manager.start_session(
            f"classify {note_path}",
            {
                "note_path": str(note_path),
                "vault_path": str(config.vault_path),
                "dry_run": dry_run,
                "verbose": verbose,
                "log_file": log_file,
            },
        )

    note_path = Path(note_path)

    console.print(f"[blue]æ­£åœ¨åˆ†æç¬”è®°: {note_path}[/blue]")

    try:
        # è¯»å–ç¬”è®°å†…å®¹
        with open(note_path, "r", encoding="utf-8") as f:
            note_content = f.read()

        # è·å– PARA ç»“æ„
        scanner = DirectoryScanner(config.vault_path, config.para_paths)
        scan_result = scanner.scan()
        para_structure = scanner.generate_structure_summary(scan_result)

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        llm_client = LLMClient(
            config, verbose=verbose, log_file_manager=_log_manager if log_file else None
        )

        console.print("[yellow]æ­£åœ¨ä½¿ç”¨ AI åˆ†æç¬”è®°...[/yellow]")
        console.print(
            f"[dim]ä½¿ç”¨æä¾›å•†: {config.llm_provider} | æ¨¡å‹: {config.llm_model}[/dim]"
        )

        # è°ƒç”¨ AI åˆ†ç±»
        result = llm_client.classify_note(note_content, para_structure)

        if not result["success"]:
            console.print(f"[red]AI åˆ†æå¤±è´¥: {result['error']}[/red]")
            if "raw_response" in result:
                console.print(f"[dim]åŸå§‹å“åº”: {result['raw_response'][:200]}...[/dim]")
            return

        classification = result["classification"]

        # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
        _display_classification_result(classification, result)

        # ç”¨æˆ·ç¡®è®¤
        if classification.get("confidence", 0) < 0.7:
            console.print("[yellow]âš ï¸  AI å¯¹æ­¤åˆ†ç±»çš„ä¿¡å¿ƒè¾ƒä½ï¼Œè¯·ä»”ç»†æ£€æŸ¥å»ºè®®[/yellow]")

        if dry_run:
            console.print("[yellow]è¯•è¿è¡Œæ¨¡å¼ï¼šä»¥ä¸‹æ˜¯å°†è¦æ‰§è¡Œçš„æ“ä½œé¢„è§ˆ[/yellow]")
            _preview_operations(classification, note_path, config.vault_path)
        else:
            if Confirm.ask("æ˜¯å¦æ‰§è¡Œæ­¤åˆ†ç±»æ“ä½œï¼Ÿ"):
                # æ‰§è¡Œæ–‡ä»¶æ“ä½œ
                file_operator = FileOperator(dry_run=False)
                operation_result = file_operator.execute_classification(
                    note_path, classification, config.vault_path
                )

                _display_operation_result(operation_result)
            else:
                console.print("[yellow]æ“ä½œå·²å–æ¶ˆ[/yellow]")

    except Exception as e:
        console.print(f"[red]åˆ†ç±»å¤±è´¥: {e}[/red]")


def _display_classification_result(classification: dict, result: dict):
    """æ˜¾ç¤ºåˆ†ç±»ç»“æœ"""
    table = Table(title="AI åˆ†ç±»ç»“æœ")
    table.add_column("å±æ€§", style="cyan")
    table.add_column("å€¼", style="white")

    table.add_row("åˆ†ç±»", classification.get("category", "æœªçŸ¥").upper())
    table.add_row("å­åˆ†ç±»", classification.get("subcategory", "æœªæŒ‡å®š"))
    table.add_row("ç›®æ ‡è·¯å¾„", classification.get("target_path", "æœªæŒ‡å®š"))
    table.add_row("ä¿¡å¿ƒåº¦", f"{classification.get('confidence', 0):.2f}")
    table.add_row("æ“ä½œç±»å‹", classification.get("action_type", "move"))

    console.print(table)

    # æ˜¾ç¤ºåˆ†ç±»ç†ç”±
    reasoning = classification.get("reasoning", "æ— ç†ç”±è¯´æ˜")
    console.print(Panel(reasoning, title="åˆ†ç±»ç†ç”±", expand=False))


def _preview_operations(classification: dict, source_path: Path, vault_path: Path):
    """é¢„è§ˆå°†è¦æ‰§è¡Œçš„æ“ä½œ"""
    console.print("\n[bold]å°†è¦æ‰§è¡Œçš„æ“ä½œï¼š[/bold]")

    # æ˜¾ç¤ºç›®å½•åˆ›å»ºæ“ä½œ
    create_dirs = classification.get("create_directories", [])
    if create_dirs:
        console.print("[cyan]åˆ›å»ºç›®å½•ï¼š[/cyan]")
        for dir_path in create_dirs:
            console.print(f"  ğŸ“ {vault_path / dir_path}")

    # æ˜¾ç¤ºæ–‡ä»¶ç§»åŠ¨æ“ä½œ
    target_path = classification.get("target_path", "")
    if target_path:
        console.print(f"[cyan]ç§»åŠ¨æ–‡ä»¶ï¼š[/cyan]")
        console.print(f"  ğŸ“„ {source_path} â†’ {vault_path / target_path}")


def _display_operation_result(operation_result: dict):
    """æ˜¾ç¤ºæ“ä½œæ‰§è¡Œç»“æœ"""
    if operation_result["success"]:
        console.print(
            f"[green]âœ… åˆ†ç±»å®Œæˆï¼æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {operation_result['final_path']}[/green]"
        )
    else:
        console.print(f"[red]âŒ æ“ä½œå¤±è´¥: {operation_result['error']}[/red]")

    # æ˜¾ç¤ºæ“ä½œè¯¦æƒ…
    operations = operation_result.get("operations", [])
    if operations:
        console.print("\n[bold]æ“ä½œè¯¦æƒ…ï¼š[/bold]")
        for i, op in enumerate(operations, 1):
            status = "âœ…" if op["success"] else "âŒ"
            op_type = op["operation"].replace("_", " ").title()
            console.print(f"  {i}. {status} {op_type}")
            if "error" in op and op["error"]:
                console.print(f"     [red]é”™è¯¯: {op['error']}[/red]")


@cli.command()
@click.pass_context
def optimize(ctx):
    """ä¼˜åŒ–æ•´ä½“ PARA ç»“æ„"""
    config = ctx.obj["config"]
    dry_run = ctx.obj["dry_run"]
    verbose = ctx.obj["verbose"]
    log_file = ctx.obj["log_file"]

    # åˆå§‹åŒ–æ—¥å¿—ä¼šè¯
    if log_file:
        _log_manager.start_session(
            "optimize",
            {
                "vault_path": str(config.vault_path),
                "para_paths": config.para_paths,
                "dry_run": dry_run,
                "verbose": verbose,
                "log_file": log_file,
            },
        )

    console.print("[blue]æ­£åœ¨åˆ†ææ•´ä½“ PARA ç»“æ„...[/blue]")

    if not Confirm.ask("è¿™å°†åˆ†æä½ çš„æ•´ä¸ªçŸ¥è¯†åº“ç»“æ„ï¼Œç»§ç»­å—ï¼Ÿ"):
        console.print("æ“ä½œå·²å–æ¶ˆ")
        return

    try:
        # æ‰«æç›®å½•ç»“æ„
        verbose_log("å¼€å§‹æ‰«æç›®å½•ç»“æ„", verbose)
        scanner = DirectoryScanner(config.vault_path, config.para_paths)
        scan_result = scanner.scan()

        verbose_log_json(
            "ç›®å½•æ‰«æç»“æœ",
            {
                "para_paths": config.para_paths,
                "vault_path": str(config.vault_path),
                "scan_summary": {
                    path: {
                        "note_count": info.note_count,
                        "subdirs": [
                            {"name": sub.name, "note_count": sub.note_count}
                            for sub in info.subdirs
                        ],
                    }
                    for path, info in scan_result.items()
                },
            },
            verbose,
        )

        para_structure = scanner.generate_structure_summary(scan_result)
        verbose_log(f"ç”Ÿæˆçš„PARAç»“æ„æ‘˜è¦:\n{para_structure}", verbose)

        # ç”Ÿæˆç¬”è®°æ¦‚è§ˆ
        notes_overview = _generate_notes_overview(scan_result)
        verbose_log(f"ç”Ÿæˆçš„ç¬”è®°æ¦‚è§ˆ:\n{notes_overview}", verbose)

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯å’Œæ–‡ä»¶æ“ä½œå™¨
        verbose_log(
            f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ - æä¾›å•†: {config.llm_provider}, æ¨¡å‹: {config.llm_model}",
            verbose,
        )
        llm_client = LLMClient(
            config, verbose=verbose, log_file_manager=_log_manager if log_file else None
        )
        file_operator = FileOperator(dry_run=dry_run)

        # åŠ è½½å»ºè®®å†å²
        verbose_log("åŠ è½½å»ºè®®å†å²", verbose)
        file_operator.load_suggestion_history()

        console.print("[yellow]æ­£åœ¨ä½¿ç”¨ AI åˆ†æç»“æ„ä¼˜åŒ–æœºä¼š...[/yellow]")
        console.print(
            f"[dim]ä½¿ç”¨æä¾›å•†: {config.llm_provider} | æ¨¡å‹: {config.llm_model}[/dim]"
        )

        # è®°å½•LLMè¯·æ±‚
        verbose_log("å‡†å¤‡å‘é€LLMè¯·æ±‚è¿›è¡Œç»“æ„åˆ†æ", verbose)
        verbose_log_json(
            "LLMè¯·æ±‚å‚æ•°",
            {
                "para_structure_length": len(para_structure),
                "notes_overview_length": len(notes_overview),
                "provider": config.llm_provider,
                "model": config.llm_model,
            },
            verbose,
        )

        # è°ƒç”¨ç»“æ„ä¼˜åŒ–åˆ†æ
        result = llm_client.optimize_structure(para_structure, notes_overview)

        verbose_log_json("LLMå®Œæ•´å“åº”", result, verbose)

        if not result["success"]:
            console.print(f"[red]ç»“æ„åˆ†æå¤±è´¥: {result['error']}[/red]")
            verbose_log(f"å¤±è´¥è¯¦æƒ…: {result}", verbose, "error")
            return

        optimization = result["optimization"]
        verbose_log_json("è§£æåçš„ä¼˜åŒ–å»ºè®®", optimization, verbose)

        # æ˜¾ç¤ºæ•´ä½“è¯„ä¼°
        _display_structure_assessment(optimization)

        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        suggestions = optimization.get("suggestions", [])
        if not suggestions:
            console.print(
                "[green]ğŸ‰ ä½ çš„ PARA ç»“æ„çœ‹èµ·æ¥å¾ˆä¸é”™ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®ï¼[/green]"
            )
            return

        console.print(f"\n[bold]å‘ç° {len(suggestions)} æ¡ä¼˜åŒ–å»ºè®®ï¼š[/bold]")
        verbose_log(f"å»ºè®®æ€»æ•°: {len(suggestions)}", verbose)

        # é€æ¡å¤„ç†å»ºè®®
        for i, suggestion in enumerate(suggestions, 1):
            verbose_log_json(f"å¤„ç†å»ºè®® {i}", suggestion, verbose)

            console.print(f"\n[bold cyan]å»ºè®® {i}/{len(suggestions)}:[/bold cyan]")
            _display_optimization_suggestion(suggestion)

            if dry_run:
                console.print("[yellow]è¯•è¿è¡Œæ¨¡å¼ï¼šæ˜¾ç¤ºå»ºè®®ä½†ä¸æ‰§è¡Œæ“ä½œ[/yellow]")
                continue

            # ç”¨æˆ·é€‰æ‹©
            console.print(
                "[dim]é€‰é¡¹: y=æ‰§è¡Œ, n=è·³è¿‡, d=ä¸AIè®¨è®º, s=å…¨éƒ¨è·³è¿‡, q=é€€å‡º[/dim]"
            )
            choice = click.prompt(
                "é€‰æ‹©æ“ä½œ",
                type=click.Choice(["y", "n", "d", "s", "q"]),
                default="n",
                show_choices=True,
            )

            verbose_log(f"ç”¨æˆ·é€‰æ‹©: {choice}", verbose)

            if choice == "q":
                console.print("é€€å‡ºä¼˜åŒ–æ¨¡å¼")
                break
            elif choice == "s":
                console.print("è·³è¿‡å‰©ä½™æ‰€æœ‰å»ºè®®")
                break
            elif choice == "d":
                verbose_log("è¿›å…¥äº¤äº’å¼è®¨è®ºæ¨¡å¼", verbose)
                # è¿›å…¥ä¸AIçš„äº¤äº’å¼è®¨è®º
                final_suggestion = _interactive_discussion(llm_client, suggestion)
                if final_suggestion:
                    # è®°å½•å»ºè®®å†å²
                    conversation_history = (
                        llm_client.conversation_history
                        if hasattr(llm_client, "conversation_history")
                        else []
                    )
                    verbose_log_json(
                        "å¯¹è¯å†å²", {"conversation": conversation_history}, verbose
                    )

                    file_operator.record_suggestion_history(
                        original_suggestion=suggestion,
                        final_suggestion=final_suggestion,
                        conversation_history=conversation_history,
                        user_decision="discussed",
                    )

                    # æ˜¾ç¤ºæœ€ç»ˆå»ºè®®
                    console.print("\n[bold cyan]è®¨è®ºåçš„æœ€ç»ˆå»ºè®®ï¼š[/bold cyan]")
                    _display_optimization_suggestion(final_suggestion)

                    if Confirm.ask("æ‰§è¡Œè¿™ä¸ªæœ€ç»ˆå»ºè®®å—ï¼Ÿ"):
                        file_operator.record_suggestion_history(
                            original_suggestion=suggestion,
                            final_suggestion=final_suggestion,
                            conversation_history=conversation_history,
                            user_decision="accepted",
                        )
                        console.print("[yellow]ä¼˜åŒ–æ“ä½œæ‰§è¡ŒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...[/yellow]")
                    else:
                        file_operator.record_suggestion_history(
                            original_suggestion=suggestion,
                            final_suggestion=final_suggestion,
                            conversation_history=conversation_history,
                            user_decision="rejected_after_discussion",
                        )
                        console.print("è·³è¿‡æ­¤å»ºè®®")
                else:
                    # è®°å½•å–æ¶ˆçš„è®¨è®º
                    file_operator.record_suggestion_history(
                        original_suggestion=suggestion,
                        user_decision="discussion_cancelled",
                    )
                    console.print("[yellow]è®¨è®ºå·²å–æ¶ˆ[/yellow]")
            elif choice == "y":
                # è®°å½•ç›´æ¥æ¥å—çš„å»ºè®®
                file_operator.record_suggestion_history(
                    original_suggestion=suggestion, user_decision="accepted_directly"
                )
                # è¿™é‡Œåº”è¯¥æ‰§è¡Œå…·ä½“çš„ä¼˜åŒ–æ“ä½œ
                console.print("[yellow]ä¼˜åŒ–æ“ä½œæ‰§è¡ŒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...[/yellow]")
            else:
                # è®°å½•è·³è¿‡çš„å»ºè®®
                file_operator.record_suggestion_history(
                    original_suggestion=suggestion, user_decision="skipped"
                )
                console.print("è·³è¿‡æ­¤å»ºè®®")

    except Exception as e:
        console.print(f"[red]ç»“æ„ä¼˜åŒ–å¤±è´¥: {e}[/red]")
        verbose_log(f"å¼‚å¸¸è¯¦æƒ…: {str(e)}", verbose, "error")
        if verbose:
            import traceback

            verbose_log(f"å®Œæ•´å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}", verbose, "error")


def _generate_notes_overview(scan_result: dict) -> str:
    """ç”Ÿæˆç¬”è®°æ¦‚è§ˆä¿¡æ¯"""
    overview_lines = ["# ç¬”è®°æ¦‚è§ˆ\n"]

    total_notes = 0
    for para_type, dir_info in scan_result.items():
        total_notes += dir_info.note_count
        overview_lines.append(f"## {para_type.upper()}: {dir_info.note_count} ç¯‡ç¬”è®°")

        # æ·»åŠ å­ç›®å½•ä¿¡æ¯
        if dir_info.subdirs:
            for subdir in dir_info.subdirs:
                overview_lines.append(f"  - {subdir.name}: {subdir.note_count} ç¯‡")

    overview_lines.insert(1, f"æ€»ç¬”è®°æ•°: {total_notes}\n")
    return "\n".join(overview_lines)


def _display_structure_assessment(optimization: dict):
    """æ˜¾ç¤ºç»“æ„è¯„ä¼°ç»“æœ"""
    assessment = optimization.get("overall_assessment", "æ— è¯„ä¼°")
    score = optimization.get("structure_score", 0)
    issues = optimization.get("main_issues", [])

    # è¯„ä¼°é¢æ¿
    assessment_text = f"[bold]æ•´ä½“è¯„ä¼°ï¼š[/bold]{assessment}\n"
    assessment_text += f"[bold]ç»“æ„è¯„åˆ†ï¼š[/bold]{score:.2f}/1.0\n"

    if issues:
        assessment_text += f"\n[bold]ä¸»è¦é—®é¢˜ï¼š[/bold]\n"
        for issue in issues:
            assessment_text += f"â€¢ {issue}\n"

    console.print(Panel(assessment_text, title="PARA ç»“æ„åˆ†æ", expand=False))


def _display_optimization_suggestion(suggestion: dict):
    """æ˜¾ç¤ºå•ä¸ªä¼˜åŒ–å»ºè®®"""
    suggestion_type = suggestion.get("type", "unknown")
    priority = suggestion.get("priority", "medium")
    description = suggestion.get("description", "æ— æè¿°")
    reasoning = suggestion.get("reasoning", "æ— ç†ç”±")
    current_path = suggestion.get("current_path", "")
    suggested_path = suggestion.get("suggested_path", "")

    # ä¼˜å…ˆçº§é¢œè‰²
    priority_colors = {"high": "red", "medium": "yellow", "low": "green"}
    priority_color = priority_colors.get(priority, "white")

    table = Table(title=f"{suggestion_type.upper()} å»ºè®®")
    table.add_column("å±æ€§", style="cyan")
    table.add_column("å€¼", style="white")

    table.add_row("ä¼˜å…ˆçº§", f"[{priority_color}]{priority.upper()}[/{priority_color}]")
    table.add_row("æè¿°", description)
    if current_path:
        table.add_row("å½“å‰è·¯å¾„", current_path)
    if suggested_path:
        table.add_row("å»ºè®®è·¯å¾„", suggested_path)

    console.print(table)
    console.print(Panel(reasoning, title="å»ºè®®ç†ç”±", expand=False))


def _interactive_discussion(llm_client: LLMClient, suggestion: dict) -> Optional[dict]:
    """ä¸AIè¿›è¡Œäº¤äº’å¼å»ºè®®è®¨è®º

    Args:
        llm_client: LLMå®¢æˆ·ç«¯
        suggestion: è¦è®¨è®ºçš„å»ºè®®

    Returns:
        æœ€ç»ˆç¡®å®šçš„å»ºè®®ï¼Œå¦‚æœå–æ¶ˆåˆ™è¿”å›None
    """
    console.print("\n[bold blue]ğŸ¤– è¿›å…¥ä¸AIçš„äº¤äº’å¼è®¨è®ºæ¨¡å¼[/bold blue]")
    console.print("[dim]ä½ å¯ä»¥å‘Šè¯‰AIä½ çš„æƒ³æ³•ã€æä¾›å‡†ç¡®ä¿¡æ¯æˆ–è¦æ±‚è°ƒæ•´å»ºè®®[/dim]")
    console.print("[dim]è¾“å…¥ 'exit' æˆ– 'quit' ç»“æŸè®¨è®º[/dim]\n")

    # å¼€å§‹å¯¹è¯
    llm_client.start_suggestion_conversation(suggestion)

    # æ˜¾ç¤ºAIçš„åˆå§‹å»ºè®®è¯´æ˜
    console.print("[bold cyan]ğŸ¤– AIï¼š[/bold cyan]")
    console.print("æˆ‘åˆšæ‰ç»™å‡ºäº†è¿™ä¸ªå»ºè®®ã€‚ä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆåœ°æ–¹éœ€è¦è°ƒæ•´å—ï¼Ÿ")
    console.print("æ¯”å¦‚ï¼Œå¦‚æœæˆ‘çŒœæµ‹çš„é¡¹ç›®åç§°æˆ–æ—¶é—´ä¸å‡†ç¡®ï¼Œè¯·å‘Šè¯‰æˆ‘æ­£ç¡®çš„ä¿¡æ¯ã€‚\n")

    conversation_count = 0
    max_conversations = 10  # é™åˆ¶å¯¹è¯è½®æ•°

    while conversation_count < max_conversations:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = click.prompt(
            f"[{conversation_count + 1}] ä½ ", default="", show_default=False
        ).strip()

        if not user_input:
            continue

        # æ£€æŸ¥æ˜¯å¦è¦é€€å‡º
        if user_input.lower() in ["exit", "quit", "é€€å‡º", "ç»“æŸ"]:
            if Confirm.ask("ç¡®å®šè¦ç»“æŸè®¨è®ºå—ï¼Ÿ"):
                console.print("[yellow]è®¨è®ºå·²ç»“æŸ[/yellow]")
                return None
            else:
                continue

        # è·å–AIå›å¤
        console.print("[dim]AIæ­£åœ¨æ€è€ƒ...[/dim]")
        result = llm_client.continue_suggestion_conversation(user_input)

        if not result["success"]:
            console.print(f"[red]å¯¹è¯å‡ºé”™: {result['error']}[/red]")
            continue

        # æ˜¾ç¤ºAIå›å¤
        console.print(f"\n[bold cyan]ğŸ¤– AIï¼š[/bold cyan]")
        console.print(result["ai_response"])

        # æ£€æŸ¥å»ºè®®æ˜¯å¦æœ‰æ›´æ–°
        updated_suggestion = result.get("updated_suggestion")
        if updated_suggestion and updated_suggestion != suggestion:
            console.print("\n[yellow]ğŸ’¡ å»ºè®®å·²æ ¹æ®ä½ çš„åé¦ˆè¿›è¡Œè°ƒæ•´[/yellow]")
            console.print("[dim]æ›´æ–°åçš„å»ºè®®ï¼š[/dim]\n")
            _display_optimization_suggestion(updated_suggestion)
            suggestion = updated_suggestion  # æ›´æ–°å½“å‰å»ºè®®

        conversation_count += 1
        console.print()  # ç©ºè¡Œåˆ†éš”

        # è¯¢é—®æ˜¯å¦æ»¡æ„å½“å‰å»ºè®®
        if conversation_count >= 3:  # è‡³å°‘è®¨è®º3è½®åè¯¢é—®
            if Confirm.ask("ä½ å¯¹å½“å‰çš„å»ºè®®æ»¡æ„å—ï¼Ÿ"):
                break

    if conversation_count >= max_conversations:
        console.print("[yellow]âš ï¸  å·²è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ•°é™åˆ¶[/yellow]")

    # è·å–æœ€ç»ˆå»ºè®®
    final_suggestion = llm_client.get_final_suggestion()

    if final_suggestion:
        console.print("\n[bold green]âœ… è®¨è®ºå®Œæˆï¼[/bold green]")
        return final_suggestion
    else:
        console.print("\n[yellow]è®¨è®ºå·²å–æ¶ˆ[/yellow]")
        return None


def main():
    """å…¥å£å‡½æ•°"""
    cli()


if __name__ == "__main__":
    main()
